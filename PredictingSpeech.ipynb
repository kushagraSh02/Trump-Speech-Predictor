{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Embedding,Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speeches\\BattleCreekDec19_2019.txt\n",
      "Speeches\\BemidjiSep18_2020.txt\n",
      "Speeches\\CharlestonFeb28_2020.txt\n",
      "Speeches\\CharlotteMar2_2020.txt\n",
      "Speeches\\CincinnatiAug1_2019.txt\n",
      "Speeches\\ColoradorSpringsFeb20_2020.txt\n",
      "Speeches\\DallasOct17_2019.txt\n",
      "Speeches\\DesMoinesJan30_2020.txt\n",
      "Speeches\\FayettevilleSep19_2020.txt\n",
      "Speeches\\FayettevilleSep9_2019.txt\n",
      "Speeches\\FreelandSep10_2020.txt\n",
      "Speeches\\GreenvilleJul17_2019.txt\n",
      "Speeches\\HendersonSep13_2020.txt\n",
      "Speeches\\HersheyDec10_2019.txt\n",
      "Speeches\\LasVegasFeb21_2020.txt\n",
      "Speeches\\LatrobeSep3_2020.txt\n",
      "Speeches\\LexingtonNov4_2019.txt\n",
      "Speeches\\MilwaukeeJan14_2020.txt\n",
      "Speeches\\MindenSep12_2020.txt\n",
      "Speeches\\MinneapolisOct10_2019.txt\n",
      "Speeches\\MosineeSep17_2020.txt\n",
      "Speeches\\NewHampshireAug15_2019.txt\n",
      "Speeches\\NewHampshireAug28_2020.txt\n",
      "Speeches\\NewHampshireFeb10_2020.txt\n",
      "Speeches\\NewMexicoSep16_2019.txt\n",
      "Speeches\\OhioSep21_2020.txt\n",
      "Speeches\\PhoenixFeb19_2020.txt\n",
      "Speeches\\PittsburghSep22_2020.txt\n",
      "Speeches\\TexasSep23_2019.txt\n",
      "Speeches\\ToledoJan9_2020.txt\n",
      "Speeches\\TulsaJun20_2020.txt\n",
      "Speeches\\TupeloNov1_2019.txt\n",
      "Speeches\\WildwoodJan28_2020.txt\n",
      "Speeches\\Winston-SalemSep8_2020.txt\n",
      "Speeches\\YumaAug18_2020.txt\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('Speeches'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Speeches\\\\BattleCreekDec19_2019.txt',\n",
       " 'Speeches\\\\BemidjiSep18_2020.txt',\n",
       " 'Speeches\\\\CharlestonFeb28_2020.txt',\n",
       " 'Speeches\\\\CharlotteMar2_2020.txt',\n",
       " 'Speeches\\\\CincinnatiAug1_2019.txt',\n",
       " 'Speeches\\\\ColoradorSpringsFeb20_2020.txt',\n",
       " 'Speeches\\\\DallasOct17_2019.txt',\n",
       " 'Speeches\\\\DesMoinesJan30_2020.txt',\n",
       " 'Speeches\\\\FayettevilleSep19_2020.txt',\n",
       " 'Speeches\\\\FayettevilleSep9_2019.txt',\n",
       " 'Speeches\\\\FreelandSep10_2020.txt',\n",
       " 'Speeches\\\\GreenvilleJul17_2019.txt',\n",
       " 'Speeches\\\\HendersonSep13_2020.txt',\n",
       " 'Speeches\\\\HersheyDec10_2019.txt',\n",
       " 'Speeches\\\\LasVegasFeb21_2020.txt',\n",
       " 'Speeches\\\\LatrobeSep3_2020.txt',\n",
       " 'Speeches\\\\LexingtonNov4_2019.txt',\n",
       " 'Speeches\\\\MilwaukeeJan14_2020.txt',\n",
       " 'Speeches\\\\MindenSep12_2020.txt',\n",
       " 'Speeches\\\\MinneapolisOct10_2019.txt',\n",
       " 'Speeches\\\\MosineeSep17_2020.txt',\n",
       " 'Speeches\\\\NewHampshireAug15_2019.txt',\n",
       " 'Speeches\\\\NewHampshireAug28_2020.txt',\n",
       " 'Speeches\\\\NewHampshireFeb10_2020.txt',\n",
       " 'Speeches\\\\NewMexicoSep16_2019.txt',\n",
       " 'Speeches\\\\OhioSep21_2020.txt',\n",
       " 'Speeches\\\\PhoenixFeb19_2020.txt',\n",
       " 'Speeches\\\\PittsburghSep22_2020.txt',\n",
       " 'Speeches\\\\TexasSep23_2019.txt',\n",
       " 'Speeches\\\\ToledoJan9_2020.txt',\n",
       " 'Speeches\\\\TulsaJun20_2020.txt',\n",
       " 'Speeches\\\\TupeloNov1_2019.txt',\n",
       " 'Speeches\\\\WildwoodJan28_2020.txt',\n",
       " 'Speeches\\\\Winston-SalemSep8_2020.txt',\n",
       " 'Speeches\\\\YumaAug18_2020.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_list = glob.glob('Speeches/*.txt')\n",
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thank you. Thank you. Thank you to Vice President Pence. He's a good guy. We've done a great job tog\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = []\n",
    "for file in files_list:\n",
    "    with open(file, 'r', encoding='utf-8') as file:\n",
    "        text.append(file.read())\n",
    "text[0][:100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9176"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text)\n",
    "\n",
    "word_text = tokenizer.word_index\n",
    "\n",
    "idx_text = tokenizer.index_word\n",
    "\n",
    "word_count = tokenizer.word_counts\n",
    "\n",
    "total_text = len(word_count)\n",
    "total_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[67, 5, 67, 5, 67]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(text)\n",
    "sequences[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "\n",
    "for seq in sequences:\n",
    "    for i in range(500):\n",
    "        extract = seq[i:i+20]\n",
    "        features.append(extract[:-1])\n",
    "        labels.append(extract[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = shuffle(features, labels, random_state=420)\n",
    "\n",
    "train_len = int(len(labels)*0.80)\n",
    "\n",
    "train_features = features[:train_len]\n",
    "train_labels = labels[:train_len]\n",
    "\n",
    "test_features = features[train_len:]\n",
    "test_labels = labels[train_len:]\n",
    "\n",
    "X_train = np.array(train_features)\n",
    "X_test = np.array(test_features)\n",
    "\n",
    "y_train = np.zeros((len(train_labels), total_text), dtype=np.int8)\n",
    "y_test = np.zeros((len(test_labels), total_text), dtype=np.int8)\n",
    "\n",
    "for example_index, word_index in enumerate(train_labels):\n",
    "    y_train[example_index, word_index] = 1\n",
    "for example_index, word_index in enumerate(test_labels):\n",
    "    y_test[example_index, word_index] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: been a problem it's called houston strong prime minister modi and i have come to houston to celebrate everything\n",
      "Label: that\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\",' '.join([idx_text[i] for i in X_train[1]]))\n",
    "print(\"Label:\",' '.join([idx_text[train_labels[1]]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 100)         917600    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, None, 128)         117248    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 9176)              596440    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,771,128\n",
      "Trainable params: 1,771,128\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=total_text, output_dim=100, trainable=True))\n",
    "model.add(LSTM(128, return_sequences=True, dropout=0.1, recurrent_dropout=0.1, activation='tanh'))\n",
    "model.add(LSTM(128, return_sequences=False, dropout=0.1, recurrent_dropout=0.1, activation='tanh'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(total_text, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "110/110 [==============================] - 14s 100ms/step - loss: 7.0861 - accuracy: 0.0284 - val_loss: 6.3725 - val_accuracy: 0.0317\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 6.2812 - accuracy: 0.0393 - val_loss: 6.3458 - val_accuracy: 0.0466\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 6.2124 - accuracy: 0.0404 - val_loss: 6.3877 - val_accuracy: 0.0466\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 6.1835 - accuracy: 0.0398 - val_loss: 6.3603 - val_accuracy: 0.0466\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 6.1650 - accuracy: 0.0403 - val_loss: 6.3689 - val_accuracy: 0.0466\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 6.1141 - accuracy: 0.0404 - val_loss: 6.2869 - val_accuracy: 0.0466\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 6.0146 - accuracy: 0.0390 - val_loss: 6.3292 - val_accuracy: 0.0466\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 5.9654 - accuracy: 0.0410 - val_loss: 6.3204 - val_accuracy: 0.0449\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 6.0764 - accuracy: 0.0409 - val_loss: 6.2924 - val_accuracy: 0.0431\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 5.9162 - accuracy: 0.0445 - val_loss: 6.2477 - val_accuracy: 0.0517\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 5.8466 - accuracy: 0.0473 - val_loss: 6.2433 - val_accuracy: 0.0489\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 5.8023 - accuracy: 0.0509 - val_loss: 6.2451 - val_accuracy: 0.0543\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 5.7392 - accuracy: 0.0508 - val_loss: 6.2501 - val_accuracy: 0.0566\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 5.7271 - accuracy: 0.0509 - val_loss: 6.2619 - val_accuracy: 0.0554\n",
      "Epoch 15/500\n",
      "110/110 [==============================] - 12s 114ms/step - loss: 5.6888 - accuracy: 0.0546 - val_loss: 6.2763 - val_accuracy: 0.0577\n",
      "Epoch 16/500\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 5.6636 - accuracy: 0.0583 - val_loss: 6.2696 - val_accuracy: 0.0560\n",
      "Epoch 17/500\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 5.6264 - accuracy: 0.0595 - val_loss: 6.2907 - val_accuracy: 0.0566\n",
      "Epoch 18/500\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 5.5957 - accuracy: 0.0598 - val_loss: 6.2949 - val_accuracy: 0.0611\n",
      "Epoch 19/500\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 5.5576 - accuracy: 0.0640 - val_loss: 6.3506 - val_accuracy: 0.0589\n",
      "Epoch 20/500\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 5.5361 - accuracy: 0.0637 - val_loss: 6.3066 - val_accuracy: 0.0643\n",
      "Epoch 21/500\n",
      "110/110 [==============================] - 14s 128ms/step - loss: 5.5080 - accuracy: 0.0671 - val_loss: 6.3022 - val_accuracy: 0.0651\n",
      "Epoch 22/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 5.4794 - accuracy: 0.0670 - val_loss: 6.2944 - val_accuracy: 0.0649\n",
      "Epoch 23/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 5.4561 - accuracy: 0.0696 - val_loss: 6.3457 - val_accuracy: 0.0666\n",
      "Epoch 24/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 5.4133 - accuracy: 0.0704 - val_loss: 6.3410 - val_accuracy: 0.0674\n",
      "Epoch 25/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 5.4007 - accuracy: 0.0700 - val_loss: 6.3652 - val_accuracy: 0.0663\n",
      "Epoch 26/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 5.3785 - accuracy: 0.0720 - val_loss: 6.3698 - val_accuracy: 0.0689\n",
      "Epoch 27/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 5.3536 - accuracy: 0.0752 - val_loss: 6.4373 - val_accuracy: 0.0677\n",
      "Epoch 28/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 5.3225 - accuracy: 0.0759 - val_loss: 6.4583 - val_accuracy: 0.0700\n",
      "Epoch 29/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 5.2930 - accuracy: 0.0766 - val_loss: 6.4660 - val_accuracy: 0.0697\n",
      "Epoch 30/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 5.2740 - accuracy: 0.0764 - val_loss: 6.4444 - val_accuracy: 0.0686\n",
      "Epoch 31/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 5.2393 - accuracy: 0.0776 - val_loss: 6.5465 - val_accuracy: 0.0709\n",
      "Epoch 32/500\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 5.2222 - accuracy: 0.0785 - val_loss: 6.4953 - val_accuracy: 0.0731\n",
      "Epoch 33/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 5.2078 - accuracy: 0.0814 - val_loss: 6.5574 - val_accuracy: 0.0706\n",
      "Epoch 34/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 5.1717 - accuracy: 0.0833 - val_loss: 6.5793 - val_accuracy: 0.0723\n",
      "Epoch 35/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 5.1428 - accuracy: 0.0836 - val_loss: 6.6300 - val_accuracy: 0.0751\n",
      "Epoch 36/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 5.1294 - accuracy: 0.0848 - val_loss: 6.5610 - val_accuracy: 0.0740\n",
      "Epoch 37/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 5.1115 - accuracy: 0.0858 - val_loss: 6.6692 - val_accuracy: 0.0740\n",
      "Epoch 38/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 5.0828 - accuracy: 0.0880 - val_loss: 6.6702 - val_accuracy: 0.0794\n",
      "Epoch 39/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 5.0673 - accuracy: 0.0881 - val_loss: 6.7401 - val_accuracy: 0.0780\n",
      "Epoch 40/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 5.0276 - accuracy: 0.0906 - val_loss: 6.7352 - val_accuracy: 0.0763\n",
      "Epoch 41/500\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 5.0127 - accuracy: 0.0939 - val_loss: 6.7884 - val_accuracy: 0.0789\n",
      "Epoch 42/500\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 4.9901 - accuracy: 0.0945 - val_loss: 6.7743 - val_accuracy: 0.0803\n",
      "Epoch 43/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 4.9952 - accuracy: 0.0939 - val_loss: 6.8179 - val_accuracy: 0.0763\n",
      "Epoch 44/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.9802 - accuracy: 0.0944 - val_loss: 6.8667 - val_accuracy: 0.0826\n",
      "Epoch 45/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.9458 - accuracy: 0.0987 - val_loss: 6.9411 - val_accuracy: 0.0814\n",
      "Epoch 46/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.9366 - accuracy: 0.1011 - val_loss: 6.9164 - val_accuracy: 0.0826\n",
      "Epoch 47/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.8943 - accuracy: 0.0990 - val_loss: 6.9888 - val_accuracy: 0.0811\n",
      "Epoch 48/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.8682 - accuracy: 0.1025 - val_loss: 7.0584 - val_accuracy: 0.0829\n",
      "Epoch 49/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.8483 - accuracy: 0.1030 - val_loss: 7.0085 - val_accuracy: 0.0863\n",
      "Epoch 50/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.8202 - accuracy: 0.1066 - val_loss: 7.0152 - val_accuracy: 0.0860\n",
      "Epoch 51/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 4.8015 - accuracy: 0.1069 - val_loss: 7.1216 - val_accuracy: 0.0894\n",
      "Epoch 52/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 4.7888 - accuracy: 0.1086 - val_loss: 7.1275 - val_accuracy: 0.0851\n",
      "Epoch 53/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.7539 - accuracy: 0.1128 - val_loss: 7.1927 - val_accuracy: 0.0871\n",
      "Epoch 54/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.7399 - accuracy: 0.1099 - val_loss: 7.2848 - val_accuracy: 0.0886\n",
      "Epoch 55/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.9987 - accuracy: 0.1073 - val_loss: 6.8359 - val_accuracy: 0.0911\n",
      "Epoch 56/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.9134 - accuracy: 0.1056 - val_loss: 6.8710 - val_accuracy: 0.0931\n",
      "Epoch 57/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.8476 - accuracy: 0.1114 - val_loss: 6.8843 - val_accuracy: 0.0920\n",
      "Epoch 58/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.7880 - accuracy: 0.1121 - val_loss: 6.9839 - val_accuracy: 0.0957\n",
      "Epoch 59/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.7526 - accuracy: 0.1119 - val_loss: 6.9986 - val_accuracy: 0.0937\n",
      "Epoch 60/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.7249 - accuracy: 0.1156 - val_loss: 7.0508 - val_accuracy: 0.1000\n",
      "Epoch 61/500\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 4.7154 - accuracy: 0.1160 - val_loss: 7.0993 - val_accuracy: 0.0957\n",
      "Epoch 62/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.6652 - accuracy: 0.1189 - val_loss: 7.1150 - val_accuracy: 0.0986\n",
      "Epoch 63/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.6499 - accuracy: 0.1175 - val_loss: 7.1310 - val_accuracy: 0.0957\n",
      "Epoch 64/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.6279 - accuracy: 0.1216 - val_loss: 7.2015 - val_accuracy: 0.0951\n",
      "Epoch 65/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.6003 - accuracy: 0.1203 - val_loss: 7.1821 - val_accuracy: 0.0966\n",
      "Epoch 66/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.5811 - accuracy: 0.1242 - val_loss: 7.2850 - val_accuracy: 0.0926\n",
      "Epoch 67/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.5447 - accuracy: 0.1254 - val_loss: 7.3598 - val_accuracy: 0.0980\n",
      "Epoch 68/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.5220 - accuracy: 0.1284 - val_loss: 7.3388 - val_accuracy: 0.0977\n",
      "Epoch 69/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 4.5412 - accuracy: 0.1256 - val_loss: 7.3495 - val_accuracy: 0.0940\n",
      "Epoch 70/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.5150 - accuracy: 0.1246 - val_loss: 7.3903 - val_accuracy: 0.0989\n",
      "Epoch 71/500\n",
      "110/110 [==============================] - 12s 114ms/step - loss: 4.5413 - accuracy: 0.1249 - val_loss: 7.1804 - val_accuracy: 0.0923\n",
      "Epoch 72/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.5331 - accuracy: 0.1244 - val_loss: 7.5602 - val_accuracy: 0.0994\n",
      "Epoch 73/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 4.4475 - accuracy: 0.1309 - val_loss: 7.5429 - val_accuracy: 0.1009\n",
      "Epoch 74/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.4206 - accuracy: 0.1282 - val_loss: 7.5694 - val_accuracy: 0.1014\n",
      "Epoch 75/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.4042 - accuracy: 0.1291 - val_loss: 7.7404 - val_accuracy: 0.1014\n",
      "Epoch 76/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.3730 - accuracy: 0.1350 - val_loss: 7.7062 - val_accuracy: 0.1017\n",
      "Epoch 77/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.3504 - accuracy: 0.1321 - val_loss: 7.7342 - val_accuracy: 0.1026\n",
      "Epoch 78/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.3424 - accuracy: 0.1366 - val_loss: 7.7597 - val_accuracy: 0.1014\n",
      "Epoch 79/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.3133 - accuracy: 0.1379 - val_loss: 7.7360 - val_accuracy: 0.1026\n",
      "Epoch 80/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.3105 - accuracy: 0.1354 - val_loss: 7.8293 - val_accuracy: 0.1051\n",
      "Epoch 81/500\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 4.2989 - accuracy: 0.1381 - val_loss: 7.8882 - val_accuracy: 0.1006\n",
      "Epoch 82/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.2817 - accuracy: 0.1394 - val_loss: 7.7994 - val_accuracy: 0.1009\n",
      "Epoch 83/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.2589 - accuracy: 0.1421 - val_loss: 7.8443 - val_accuracy: 0.1029\n",
      "Epoch 84/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.2436 - accuracy: 0.1418 - val_loss: 7.9874 - val_accuracy: 0.1051\n",
      "Epoch 85/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.2345 - accuracy: 0.1439 - val_loss: 7.8772 - val_accuracy: 0.0994\n",
      "Epoch 86/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.2069 - accuracy: 0.1440 - val_loss: 8.0001 - val_accuracy: 0.1011\n",
      "Epoch 87/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.2029 - accuracy: 0.1423 - val_loss: 7.9824 - val_accuracy: 0.1051\n",
      "Epoch 88/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.1785 - accuracy: 0.1434 - val_loss: 8.0152 - val_accuracy: 0.1029\n",
      "Epoch 89/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.1795 - accuracy: 0.1494 - val_loss: 8.0834 - val_accuracy: 0.1071\n",
      "Epoch 90/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.1558 - accuracy: 0.1498 - val_loss: 8.1363 - val_accuracy: 0.1083\n",
      "Epoch 91/500\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 4.1415 - accuracy: 0.1516 - val_loss: 8.1927 - val_accuracy: 0.1066\n",
      "Epoch 92/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.1315 - accuracy: 0.1520 - val_loss: 8.2805 - val_accuracy: 0.1063\n",
      "Epoch 93/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.1196 - accuracy: 0.1527 - val_loss: 8.1036 - val_accuracy: 0.1069\n",
      "Epoch 94/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.1065 - accuracy: 0.1529 - val_loss: 8.3126 - val_accuracy: 0.1071\n",
      "Epoch 95/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 4.0792 - accuracy: 0.1576 - val_loss: 8.2540 - val_accuracy: 0.1086\n",
      "Epoch 96/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.0853 - accuracy: 0.1559 - val_loss: 8.3333 - val_accuracy: 0.1089\n",
      "Epoch 97/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.0658 - accuracy: 0.1597 - val_loss: 8.2766 - val_accuracy: 0.1089\n",
      "Epoch 98/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 4.0754 - accuracy: 0.1552 - val_loss: 8.2366 - val_accuracy: 0.1109\n",
      "Epoch 99/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.0767 - accuracy: 0.1549 - val_loss: 8.3575 - val_accuracy: 0.1091\n",
      "Epoch 100/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.0675 - accuracy: 0.1612 - val_loss: 8.3741 - val_accuracy: 0.1123\n",
      "Epoch 101/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 4.0701 - accuracy: 0.1553 - val_loss: 8.3168 - val_accuracy: 0.1123\n",
      "Epoch 102/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 4.0481 - accuracy: 0.1619 - val_loss: 8.5075 - val_accuracy: 0.1074\n",
      "Epoch 103/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.0466 - accuracy: 0.1594 - val_loss: 8.5609 - val_accuracy: 0.1129\n",
      "Epoch 104/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 4.0312 - accuracy: 0.1602 - val_loss: 8.5069 - val_accuracy: 0.1109\n",
      "Epoch 105/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 4.0099 - accuracy: 0.1607 - val_loss: 8.5958 - val_accuracy: 0.1114\n",
      "Epoch 106/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.9893 - accuracy: 0.1656 - val_loss: 8.6188 - val_accuracy: 0.1140\n",
      "Epoch 107/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.9811 - accuracy: 0.1642 - val_loss: 8.6829 - val_accuracy: 0.1140\n",
      "Epoch 108/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.9797 - accuracy: 0.1658 - val_loss: 8.6872 - val_accuracy: 0.1166\n",
      "Epoch 109/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.9920 - accuracy: 0.1663 - val_loss: 8.7797 - val_accuracy: 0.1106\n",
      "Epoch 110/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.9710 - accuracy: 0.1681 - val_loss: 8.6772 - val_accuracy: 0.1126\n",
      "Epoch 111/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 3.9546 - accuracy: 0.1676 - val_loss: 8.7899 - val_accuracy: 0.1166\n",
      "Epoch 112/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.9404 - accuracy: 0.1714 - val_loss: 8.6893 - val_accuracy: 0.1177\n",
      "Epoch 113/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.9306 - accuracy: 0.1691 - val_loss: 8.8697 - val_accuracy: 0.1223\n",
      "Epoch 114/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.8996 - accuracy: 0.1724 - val_loss: 8.8784 - val_accuracy: 0.1206\n",
      "Epoch 115/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.8973 - accuracy: 0.1729 - val_loss: 8.9757 - val_accuracy: 0.1171\n",
      "Epoch 116/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.8939 - accuracy: 0.1759 - val_loss: 8.8771 - val_accuracy: 0.1177\n",
      "Epoch 117/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.8722 - accuracy: 0.1740 - val_loss: 8.9577 - val_accuracy: 0.1186\n",
      "Epoch 118/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.8513 - accuracy: 0.1730 - val_loss: 9.0783 - val_accuracy: 0.1174\n",
      "Epoch 119/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 3.8347 - accuracy: 0.1801 - val_loss: 9.2793 - val_accuracy: 0.1166\n",
      "Epoch 120/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.8344 - accuracy: 0.1769 - val_loss: 9.1690 - val_accuracy: 0.1177\n",
      "Epoch 121/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 3.8078 - accuracy: 0.1854 - val_loss: 9.2473 - val_accuracy: 0.1171\n",
      "Epoch 122/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.8269 - accuracy: 0.1816 - val_loss: 9.0860 - val_accuracy: 0.1206\n",
      "Epoch 123/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.8124 - accuracy: 0.1827 - val_loss: 9.2292 - val_accuracy: 0.1211\n",
      "Epoch 124/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.7951 - accuracy: 0.1841 - val_loss: 9.1019 - val_accuracy: 0.1203\n",
      "Epoch 125/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.7885 - accuracy: 0.1852 - val_loss: 9.0570 - val_accuracy: 0.1211\n",
      "Epoch 126/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.7653 - accuracy: 0.1873 - val_loss: 9.1975 - val_accuracy: 0.1209\n",
      "Epoch 127/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 3.7602 - accuracy: 0.1888 - val_loss: 9.2073 - val_accuracy: 0.1223\n",
      "Epoch 128/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.7500 - accuracy: 0.1884 - val_loss: 9.3051 - val_accuracy: 0.1189\n",
      "Epoch 129/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.7519 - accuracy: 0.1848 - val_loss: 9.4348 - val_accuracy: 0.1217\n",
      "Epoch 130/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 3.7215 - accuracy: 0.1934 - val_loss: 9.3879 - val_accuracy: 0.1203\n",
      "Epoch 131/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 3.7109 - accuracy: 0.1929 - val_loss: 9.5181 - val_accuracy: 0.1200\n",
      "Epoch 132/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.6989 - accuracy: 0.1941 - val_loss: 9.5819 - val_accuracy: 0.1240\n",
      "Epoch 133/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.6996 - accuracy: 0.1923 - val_loss: 9.4132 - val_accuracy: 0.1197\n",
      "Epoch 134/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.7749 - accuracy: 0.1867 - val_loss: 9.4163 - val_accuracy: 0.1166\n",
      "Epoch 135/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 3.7522 - accuracy: 0.1886 - val_loss: 9.5517 - val_accuracy: 0.1174\n",
      "Epoch 136/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.7390 - accuracy: 0.1959 - val_loss: 9.4572 - val_accuracy: 0.1174\n",
      "Epoch 137/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.7021 - accuracy: 0.1932 - val_loss: 9.5693 - val_accuracy: 0.1180\n",
      "Epoch 138/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.7235 - accuracy: 0.1962 - val_loss: 9.5682 - val_accuracy: 0.1197\n",
      "Epoch 139/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.6828 - accuracy: 0.1957 - val_loss: 9.7079 - val_accuracy: 0.1186\n",
      "Epoch 140/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.6799 - accuracy: 0.1979 - val_loss: 9.7823 - val_accuracy: 0.1189\n",
      "Epoch 141/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 3.6649 - accuracy: 0.2045 - val_loss: 9.7853 - val_accuracy: 0.1211\n",
      "Epoch 142/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.6653 - accuracy: 0.1963 - val_loss: 9.6854 - val_accuracy: 0.1223\n",
      "Epoch 143/500\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 3.6582 - accuracy: 0.1979 - val_loss: 9.8186 - val_accuracy: 0.1183\n",
      "Epoch 144/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.6298 - accuracy: 0.2024 - val_loss: 9.8449 - val_accuracy: 0.1166\n",
      "Epoch 145/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.6333 - accuracy: 0.2051 - val_loss: 9.8497 - val_accuracy: 0.1186\n",
      "Epoch 146/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.6228 - accuracy: 0.2043 - val_loss: 9.8266 - val_accuracy: 0.1177\n",
      "Epoch 147/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.6381 - accuracy: 0.2057 - val_loss: 9.7753 - val_accuracy: 0.1177\n",
      "Epoch 148/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.6397 - accuracy: 0.2016 - val_loss: 9.9552 - val_accuracy: 0.1191\n",
      "Epoch 149/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.6062 - accuracy: 0.2006 - val_loss: 9.9798 - val_accuracy: 0.1197\n",
      "Epoch 150/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.6128 - accuracy: 0.2036 - val_loss: 10.1399 - val_accuracy: 0.1163\n",
      "Epoch 151/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 3.6200 - accuracy: 0.2017 - val_loss: 9.8164 - val_accuracy: 0.1197\n",
      "Epoch 152/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.6045 - accuracy: 0.2046 - val_loss: 9.9465 - val_accuracy: 0.1229\n",
      "Epoch 153/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.5714 - accuracy: 0.2107 - val_loss: 10.0571 - val_accuracy: 0.1200\n",
      "Epoch 154/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.5616 - accuracy: 0.2118 - val_loss: 10.3321 - val_accuracy: 0.1234\n",
      "Epoch 155/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.5415 - accuracy: 0.2156 - val_loss: 10.0435 - val_accuracy: 0.1220\n",
      "Epoch 156/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.5518 - accuracy: 0.2104 - val_loss: 10.1792 - val_accuracy: 0.1197\n",
      "Epoch 157/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.5348 - accuracy: 0.2150 - val_loss: 10.3345 - val_accuracy: 0.1203\n",
      "Epoch 158/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.5647 - accuracy: 0.2134 - val_loss: 10.0016 - val_accuracy: 0.1231\n",
      "Epoch 159/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.7233 - accuracy: 0.1982 - val_loss: 9.6804 - val_accuracy: 0.1194\n",
      "Epoch 160/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.6912 - accuracy: 0.2009 - val_loss: 9.8089 - val_accuracy: 0.1234\n",
      "Epoch 161/500\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 3.6350 - accuracy: 0.2105 - val_loss: 9.8876 - val_accuracy: 0.1203\n",
      "Epoch 162/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.6285 - accuracy: 0.2071 - val_loss: 9.8739 - val_accuracy: 0.1223\n",
      "Epoch 163/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.5961 - accuracy: 0.2079 - val_loss: 10.1369 - val_accuracy: 0.1266\n",
      "Epoch 164/500\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 3.5812 - accuracy: 0.2142 - val_loss: 10.1505 - val_accuracy: 0.1180\n",
      "Epoch 165/500\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 3.5698 - accuracy: 0.2132 - val_loss: 10.2244 - val_accuracy: 0.1249\n",
      "Epoch 166/500\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 3.5508 - accuracy: 0.2166 - val_loss: 10.2780 - val_accuracy: 0.1246\n",
      "Epoch 167/500\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 3.5350 - accuracy: 0.2127 - val_loss: 10.3694 - val_accuracy: 0.1283\n",
      "Epoch 168/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.5234 - accuracy: 0.2142 - val_loss: 10.3489 - val_accuracy: 0.1257\n",
      "Epoch 169/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.5086 - accuracy: 0.2194 - val_loss: 10.3561 - val_accuracy: 0.1260\n",
      "Epoch 170/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.4883 - accuracy: 0.2194 - val_loss: 10.5007 - val_accuracy: 0.1274\n",
      "Epoch 171/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 3.4591 - accuracy: 0.2264 - val_loss: 10.5028 - val_accuracy: 0.1214\n",
      "Epoch 172/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.4803 - accuracy: 0.2223 - val_loss: 10.4209 - val_accuracy: 0.1231\n",
      "Epoch 173/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.4878 - accuracy: 0.2204 - val_loss: 10.5258 - val_accuracy: 0.1246\n",
      "Epoch 174/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.4631 - accuracy: 0.2221 - val_loss: 10.6934 - val_accuracy: 0.1266\n",
      "Epoch 175/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.4420 - accuracy: 0.2254 - val_loss: 10.6499 - val_accuracy: 0.1269\n",
      "Epoch 176/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.4470 - accuracy: 0.2268 - val_loss: 10.6128 - val_accuracy: 0.1237\n",
      "Epoch 177/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.4354 - accuracy: 0.2258 - val_loss: 10.6328 - val_accuracy: 0.1237\n",
      "Epoch 178/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.4220 - accuracy: 0.2255 - val_loss: 10.6294 - val_accuracy: 0.1234\n",
      "Epoch 179/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.4020 - accuracy: 0.2302 - val_loss: 10.7239 - val_accuracy: 0.1217\n",
      "Epoch 180/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.4167 - accuracy: 0.2257 - val_loss: 10.6379 - val_accuracy: 0.1277\n",
      "Epoch 181/500\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 3.3909 - accuracy: 0.2308 - val_loss: 10.6027 - val_accuracy: 0.1257\n",
      "Epoch 182/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.4131 - accuracy: 0.2276 - val_loss: 10.6529 - val_accuracy: 0.1231\n",
      "Epoch 183/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.4293 - accuracy: 0.2267 - val_loss: 10.8324 - val_accuracy: 0.1260\n",
      "Epoch 184/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.4085 - accuracy: 0.2333 - val_loss: 10.7454 - val_accuracy: 0.1254\n",
      "Epoch 185/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.3925 - accuracy: 0.2310 - val_loss: 10.7703 - val_accuracy: 0.1269\n",
      "Epoch 186/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.3783 - accuracy: 0.2318 - val_loss: 10.9079 - val_accuracy: 0.1266\n",
      "Epoch 187/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.3756 - accuracy: 0.2371 - val_loss: 10.8225 - val_accuracy: 0.1249\n",
      "Epoch 188/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.3598 - accuracy: 0.2391 - val_loss: 11.0256 - val_accuracy: 0.1277\n",
      "Epoch 189/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.3586 - accuracy: 0.2385 - val_loss: 10.9435 - val_accuracy: 0.1286\n",
      "Epoch 190/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.3950 - accuracy: 0.2361 - val_loss: 10.8685 - val_accuracy: 0.1309\n",
      "Epoch 191/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 3.4435 - accuracy: 0.2294 - val_loss: 10.7267 - val_accuracy: 0.1269\n",
      "Epoch 192/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.4028 - accuracy: 0.2319 - val_loss: 10.9864 - val_accuracy: 0.1294\n",
      "Epoch 193/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.3947 - accuracy: 0.2349 - val_loss: 10.8820 - val_accuracy: 0.1323\n",
      "Epoch 194/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.3814 - accuracy: 0.2368 - val_loss: 10.9883 - val_accuracy: 0.1297\n",
      "Epoch 195/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.4104 - accuracy: 0.2342 - val_loss: 10.8452 - val_accuracy: 0.1254\n",
      "Epoch 196/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.3791 - accuracy: 0.2319 - val_loss: 10.8809 - val_accuracy: 0.1289\n",
      "Epoch 197/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.3778 - accuracy: 0.2351 - val_loss: 10.8983 - val_accuracy: 0.1263\n",
      "Epoch 198/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 3.3632 - accuracy: 0.2386 - val_loss: 10.7542 - val_accuracy: 0.1326\n",
      "Epoch 199/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.3610 - accuracy: 0.2374 - val_loss: 11.0929 - val_accuracy: 0.1320\n",
      "Epoch 200/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.3406 - accuracy: 0.2396 - val_loss: 10.8938 - val_accuracy: 0.1289\n",
      "Epoch 201/500\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 3.3388 - accuracy: 0.2384 - val_loss: 11.1594 - val_accuracy: 0.1266\n",
      "Epoch 202/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.3411 - accuracy: 0.2360 - val_loss: 10.9289 - val_accuracy: 0.1291\n",
      "Epoch 203/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.3334 - accuracy: 0.2358 - val_loss: 11.0237 - val_accuracy: 0.1311\n",
      "Epoch 204/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.3240 - accuracy: 0.2410 - val_loss: 11.1441 - val_accuracy: 0.1317\n",
      "Epoch 205/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.3153 - accuracy: 0.2388 - val_loss: 11.2735 - val_accuracy: 0.1303\n",
      "Epoch 206/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.3047 - accuracy: 0.2471 - val_loss: 11.0748 - val_accuracy: 0.1280\n",
      "Epoch 207/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.2867 - accuracy: 0.2485 - val_loss: 11.5033 - val_accuracy: 0.1303\n",
      "Epoch 208/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.2900 - accuracy: 0.2405 - val_loss: 11.1649 - val_accuracy: 0.1291\n",
      "Epoch 209/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.2787 - accuracy: 0.2435 - val_loss: 11.5452 - val_accuracy: 0.1320\n",
      "Epoch 210/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.2743 - accuracy: 0.2495 - val_loss: 11.3711 - val_accuracy: 0.1340\n",
      "Epoch 211/500\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 3.2557 - accuracy: 0.2451 - val_loss: 11.3209 - val_accuracy: 0.1320\n",
      "Epoch 212/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.2587 - accuracy: 0.2508 - val_loss: 11.2859 - val_accuracy: 0.1320\n",
      "Epoch 213/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.2501 - accuracy: 0.2512 - val_loss: 11.2542 - val_accuracy: 0.1329\n",
      "Epoch 214/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.2402 - accuracy: 0.2519 - val_loss: 11.4983 - val_accuracy: 0.1326\n",
      "Epoch 215/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.2224 - accuracy: 0.2573 - val_loss: 11.4711 - val_accuracy: 0.1317\n",
      "Epoch 216/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.2613 - accuracy: 0.2536 - val_loss: 11.2217 - val_accuracy: 0.1300\n",
      "Epoch 217/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.2375 - accuracy: 0.2546 - val_loss: 11.7085 - val_accuracy: 0.1326\n",
      "Epoch 218/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.2508 - accuracy: 0.2512 - val_loss: 11.4571 - val_accuracy: 0.1326\n",
      "Epoch 219/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.2222 - accuracy: 0.2547 - val_loss: 11.7014 - val_accuracy: 0.1351\n",
      "Epoch 220/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.2318 - accuracy: 0.2509 - val_loss: 11.5138 - val_accuracy: 0.1309\n",
      "Epoch 221/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 3.2232 - accuracy: 0.2563 - val_loss: 11.3753 - val_accuracy: 0.1294\n",
      "Epoch 222/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 3.2306 - accuracy: 0.2550 - val_loss: 11.6148 - val_accuracy: 0.1309\n",
      "Epoch 223/500\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 3.2126 - accuracy: 0.2566 - val_loss: 11.4660 - val_accuracy: 0.1309\n",
      "Epoch 224/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.2015 - accuracy: 0.2566 - val_loss: 11.8130 - val_accuracy: 0.1309\n",
      "Epoch 225/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.3888 - accuracy: 0.2447 - val_loss: 11.3201 - val_accuracy: 0.1351\n",
      "Epoch 226/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.3571 - accuracy: 0.2464 - val_loss: 11.2406 - val_accuracy: 0.1371\n",
      "Epoch 227/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.3172 - accuracy: 0.2501 - val_loss: 11.5698 - val_accuracy: 0.1329\n",
      "Epoch 228/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 3.2926 - accuracy: 0.2497 - val_loss: 11.5791 - val_accuracy: 0.1351\n",
      "Epoch 229/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.2714 - accuracy: 0.2521 - val_loss: 11.3997 - val_accuracy: 0.1351\n",
      "Epoch 230/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.2596 - accuracy: 0.2526 - val_loss: 11.5115 - val_accuracy: 0.1351\n",
      "Epoch 231/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 3.2459 - accuracy: 0.2486 - val_loss: 11.5792 - val_accuracy: 0.1326\n",
      "Epoch 232/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.2242 - accuracy: 0.2558 - val_loss: 11.6911 - val_accuracy: 0.1349\n",
      "Epoch 233/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.2067 - accuracy: 0.2577 - val_loss: 11.8514 - val_accuracy: 0.1351\n",
      "Epoch 234/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.2322 - accuracy: 0.2531 - val_loss: 11.3105 - val_accuracy: 0.1277\n",
      "Epoch 235/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.2893 - accuracy: 0.2537 - val_loss: 11.5901 - val_accuracy: 0.1289\n",
      "Epoch 236/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.2580 - accuracy: 0.2567 - val_loss: 11.7654 - val_accuracy: 0.1289\n",
      "Epoch 237/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.2081 - accuracy: 0.2573 - val_loss: 11.6133 - val_accuracy: 0.1297\n",
      "Epoch 238/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.2138 - accuracy: 0.2554 - val_loss: 11.7181 - val_accuracy: 0.1280\n",
      "Epoch 239/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.1967 - accuracy: 0.2583 - val_loss: 11.7088 - val_accuracy: 0.1266\n",
      "Epoch 240/500\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 3.1731 - accuracy: 0.2623 - val_loss: 11.8512 - val_accuracy: 0.1306\n",
      "Epoch 241/500\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 3.1688 - accuracy: 0.2651 - val_loss: 11.7829 - val_accuracy: 0.1286\n",
      "Epoch 242/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.1770 - accuracy: 0.2615 - val_loss: 11.6849 - val_accuracy: 0.1306\n",
      "Epoch 243/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.1793 - accuracy: 0.2655 - val_loss: 11.7921 - val_accuracy: 0.1294\n",
      "Epoch 244/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.1809 - accuracy: 0.2599 - val_loss: 11.7891 - val_accuracy: 0.1309\n",
      "Epoch 245/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.1445 - accuracy: 0.2651 - val_loss: 11.9066 - val_accuracy: 0.1326\n",
      "Epoch 246/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.1486 - accuracy: 0.2620 - val_loss: 11.7938 - val_accuracy: 0.1329\n",
      "Epoch 247/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.1376 - accuracy: 0.2679 - val_loss: 12.1836 - val_accuracy: 0.1294\n",
      "Epoch 248/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.1278 - accuracy: 0.2632 - val_loss: 11.9390 - val_accuracy: 0.1291\n",
      "Epoch 249/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.1016 - accuracy: 0.2684 - val_loss: 12.0431 - val_accuracy: 0.1314\n",
      "Epoch 250/500\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 3.1177 - accuracy: 0.2686 - val_loss: 12.1157 - val_accuracy: 0.1280\n",
      "Epoch 251/500\n",
      "110/110 [==============================] - 12s 114ms/step - loss: 3.1128 - accuracy: 0.2664 - val_loss: 12.2062 - val_accuracy: 0.1280\n",
      "Epoch 252/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.1101 - accuracy: 0.2700 - val_loss: 11.9320 - val_accuracy: 0.1303\n",
      "Epoch 253/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.1556 - accuracy: 0.2672 - val_loss: 11.8842 - val_accuracy: 0.1314\n",
      "Epoch 254/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.1398 - accuracy: 0.2651 - val_loss: 12.1635 - val_accuracy: 0.1291\n",
      "Epoch 255/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.1059 - accuracy: 0.2709 - val_loss: 12.4130 - val_accuracy: 0.1286\n",
      "Epoch 256/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.1068 - accuracy: 0.2665 - val_loss: 12.2813 - val_accuracy: 0.1274\n",
      "Epoch 257/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.1006 - accuracy: 0.2716 - val_loss: 12.3754 - val_accuracy: 0.1291\n",
      "Epoch 258/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.1079 - accuracy: 0.2703 - val_loss: 12.0745 - val_accuracy: 0.1309\n",
      "Epoch 259/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.0922 - accuracy: 0.2687 - val_loss: 12.1191 - val_accuracy: 0.1294\n",
      "Epoch 260/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.1945 - accuracy: 0.2631 - val_loss: 12.0779 - val_accuracy: 0.1306\n",
      "Epoch 261/500\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 3.2564 - accuracy: 0.2583 - val_loss: 11.9764 - val_accuracy: 0.1323\n",
      "Epoch 262/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.1952 - accuracy: 0.2641 - val_loss: 12.2169 - val_accuracy: 0.1320\n",
      "Epoch 263/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.1150 - accuracy: 0.2710 - val_loss: 12.1437 - val_accuracy: 0.1303\n",
      "Epoch 264/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.0969 - accuracy: 0.2727 - val_loss: 12.3449 - val_accuracy: 0.1326\n",
      "Epoch 265/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.0872 - accuracy: 0.2736 - val_loss: 12.1845 - val_accuracy: 0.1329\n",
      "Epoch 266/500\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 3.2331 - accuracy: 0.2660 - val_loss: 12.0802 - val_accuracy: 0.1346\n",
      "Epoch 267/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.1795 - accuracy: 0.2677 - val_loss: 11.8097 - val_accuracy: 0.1303\n",
      "Epoch 268/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.1800 - accuracy: 0.2659 - val_loss: 11.9473 - val_accuracy: 0.1329\n",
      "Epoch 269/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.1551 - accuracy: 0.2698 - val_loss: 12.0292 - val_accuracy: 0.1371\n",
      "Epoch 270/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.1501 - accuracy: 0.2683 - val_loss: 12.0295 - val_accuracy: 0.1340\n",
      "Epoch 271/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 3.1471 - accuracy: 0.2679 - val_loss: 11.9912 - val_accuracy: 0.1343\n",
      "Epoch 272/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.1245 - accuracy: 0.2743 - val_loss: 12.2312 - val_accuracy: 0.1363\n",
      "Epoch 273/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.0872 - accuracy: 0.2796 - val_loss: 12.3689 - val_accuracy: 0.1354\n",
      "Epoch 274/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.0903 - accuracy: 0.2769 - val_loss: 12.2313 - val_accuracy: 0.1357\n",
      "Epoch 275/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.1032 - accuracy: 0.2759 - val_loss: 12.1307 - val_accuracy: 0.1360\n",
      "Epoch 276/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.0831 - accuracy: 0.2789 - val_loss: 12.1324 - val_accuracy: 0.1371\n",
      "Epoch 277/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.0729 - accuracy: 0.2796 - val_loss: 12.4293 - val_accuracy: 0.1306\n",
      "Epoch 278/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 3.0622 - accuracy: 0.2794 - val_loss: 12.4040 - val_accuracy: 0.1331\n",
      "Epoch 279/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.0788 - accuracy: 0.2809 - val_loss: 12.3104 - val_accuracy: 0.1340\n",
      "Epoch 280/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 3.0630 - accuracy: 0.2831 - val_loss: 12.4988 - val_accuracy: 0.1326\n",
      "Epoch 281/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 3.0489 - accuracy: 0.2777 - val_loss: 12.1914 - val_accuracy: 0.1306\n",
      "Epoch 282/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.0550 - accuracy: 0.2791 - val_loss: 12.3803 - val_accuracy: 0.1371\n",
      "Epoch 283/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.0359 - accuracy: 0.2837 - val_loss: 12.4260 - val_accuracy: 0.1331\n",
      "Epoch 284/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.0133 - accuracy: 0.2794 - val_loss: 12.6670 - val_accuracy: 0.1360\n",
      "Epoch 285/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.0301 - accuracy: 0.2835 - val_loss: 12.6590 - val_accuracy: 0.1337\n",
      "Epoch 286/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 3.0319 - accuracy: 0.2823 - val_loss: 12.4805 - val_accuracy: 0.1369\n",
      "Epoch 287/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 3.0054 - accuracy: 0.2873 - val_loss: 12.4313 - val_accuracy: 0.1369\n",
      "Epoch 288/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.9898 - accuracy: 0.2904 - val_loss: 12.3346 - val_accuracy: 0.1351\n",
      "Epoch 289/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.9816 - accuracy: 0.2887 - val_loss: 12.6734 - val_accuracy: 0.1371\n",
      "Epoch 290/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.9964 - accuracy: 0.2893 - val_loss: 12.4952 - val_accuracy: 0.1331\n",
      "Epoch 291/500\n",
      "110/110 [==============================] - 12s 114ms/step - loss: 2.9782 - accuracy: 0.2911 - val_loss: 12.5226 - val_accuracy: 0.1343\n",
      "Epoch 292/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.9820 - accuracy: 0.2939 - val_loss: 12.6255 - val_accuracy: 0.1371\n",
      "Epoch 293/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.9831 - accuracy: 0.2924 - val_loss: 12.6866 - val_accuracy: 0.1354\n",
      "Epoch 294/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.9652 - accuracy: 0.2921 - val_loss: 12.7587 - val_accuracy: 0.1386\n",
      "Epoch 295/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.9680 - accuracy: 0.2865 - val_loss: 12.9325 - val_accuracy: 0.1366\n",
      "Epoch 296/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.9547 - accuracy: 0.2974 - val_loss: 12.7697 - val_accuracy: 0.1363\n",
      "Epoch 297/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.9417 - accuracy: 0.2979 - val_loss: 12.5670 - val_accuracy: 0.1343\n",
      "Epoch 298/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.9420 - accuracy: 0.2953 - val_loss: 12.6706 - val_accuracy: 0.1369\n",
      "Epoch 299/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.9293 - accuracy: 0.2944 - val_loss: 12.7465 - val_accuracy: 0.1331\n",
      "Epoch 300/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.9364 - accuracy: 0.2948 - val_loss: 12.6735 - val_accuracy: 0.1360\n",
      "Epoch 301/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 2.9257 - accuracy: 0.2981 - val_loss: 12.6685 - val_accuracy: 0.1331\n",
      "Epoch 302/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.9275 - accuracy: 0.2965 - val_loss: 12.8675 - val_accuracy: 0.1360\n",
      "Epoch 303/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.9151 - accuracy: 0.2972 - val_loss: 12.7005 - val_accuracy: 0.1357\n",
      "Epoch 304/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.9129 - accuracy: 0.3020 - val_loss: 13.1421 - val_accuracy: 0.1326\n",
      "Epoch 305/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.8965 - accuracy: 0.2975 - val_loss: 12.8165 - val_accuracy: 0.1377\n",
      "Epoch 306/500\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 2.8942 - accuracy: 0.2968 - val_loss: 13.0124 - val_accuracy: 0.1331\n",
      "Epoch 307/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.8929 - accuracy: 0.3029 - val_loss: 12.8337 - val_accuracy: 0.1337\n",
      "Epoch 308/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.8918 - accuracy: 0.2995 - val_loss: 12.9900 - val_accuracy: 0.1383\n",
      "Epoch 309/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.8684 - accuracy: 0.3041 - val_loss: 13.2938 - val_accuracy: 0.1346\n",
      "Epoch 310/500\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 2.8774 - accuracy: 0.3047 - val_loss: 13.2844 - val_accuracy: 0.1366\n",
      "Epoch 311/500\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 2.8631 - accuracy: 0.3048 - val_loss: 12.7693 - val_accuracy: 0.1354\n",
      "Epoch 312/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.8566 - accuracy: 0.3067 - val_loss: 13.1729 - val_accuracy: 0.1360\n",
      "Epoch 313/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.8523 - accuracy: 0.3099 - val_loss: 13.5059 - val_accuracy: 0.1346\n",
      "Epoch 314/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.8681 - accuracy: 0.3055 - val_loss: 13.0084 - val_accuracy: 0.1354\n",
      "Epoch 315/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.8300 - accuracy: 0.3099 - val_loss: 13.3816 - val_accuracy: 0.1323\n",
      "Epoch 316/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.8241 - accuracy: 0.3122 - val_loss: 13.3590 - val_accuracy: 0.1371\n",
      "Epoch 317/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.8343 - accuracy: 0.3054 - val_loss: 13.2717 - val_accuracy: 0.1346\n",
      "Epoch 318/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.8275 - accuracy: 0.3123 - val_loss: 13.0545 - val_accuracy: 0.1377\n",
      "Epoch 319/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.8373 - accuracy: 0.3131 - val_loss: 13.0382 - val_accuracy: 0.1343\n",
      "Epoch 320/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.8187 - accuracy: 0.3105 - val_loss: 13.3632 - val_accuracy: 0.1354\n",
      "Epoch 321/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 2.8113 - accuracy: 0.3129 - val_loss: 13.2980 - val_accuracy: 0.1360\n",
      "Epoch 322/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.8086 - accuracy: 0.3183 - val_loss: 13.1420 - val_accuracy: 0.1354\n",
      "Epoch 323/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.8053 - accuracy: 0.3141 - val_loss: 13.2098 - val_accuracy: 0.1354\n",
      "Epoch 324/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.7781 - accuracy: 0.3181 - val_loss: 13.6910 - val_accuracy: 0.1343\n",
      "Epoch 325/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.7872 - accuracy: 0.3164 - val_loss: 13.2345 - val_accuracy: 0.1334\n",
      "Epoch 326/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 2.7835 - accuracy: 0.3161 - val_loss: 13.8382 - val_accuracy: 0.1343\n",
      "Epoch 327/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 2.7519 - accuracy: 0.3211 - val_loss: 13.8454 - val_accuracy: 0.1354\n",
      "Epoch 328/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.7731 - accuracy: 0.3154 - val_loss: 13.6324 - val_accuracy: 0.1377\n",
      "Epoch 329/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.7657 - accuracy: 0.3181 - val_loss: 13.8002 - val_accuracy: 0.1343\n",
      "Epoch 330/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.7638 - accuracy: 0.3197 - val_loss: 13.4443 - val_accuracy: 0.1389\n",
      "Epoch 331/500\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 2.7415 - accuracy: 0.3199 - val_loss: 13.8316 - val_accuracy: 0.1357\n",
      "Epoch 332/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.7499 - accuracy: 0.3211 - val_loss: 13.8336 - val_accuracy: 0.1394\n",
      "Epoch 333/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 2.7446 - accuracy: 0.3245 - val_loss: 13.5780 - val_accuracy: 0.1363\n",
      "Epoch 334/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.7380 - accuracy: 0.3232 - val_loss: 13.7300 - val_accuracy: 0.1351\n",
      "Epoch 335/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.7446 - accuracy: 0.3217 - val_loss: 13.8097 - val_accuracy: 0.1414\n",
      "Epoch 336/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.7550 - accuracy: 0.3244 - val_loss: 13.7014 - val_accuracy: 0.1366\n",
      "Epoch 337/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.7540 - accuracy: 0.3254 - val_loss: 13.6508 - val_accuracy: 0.1354\n",
      "Epoch 338/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.7227 - accuracy: 0.3286 - val_loss: 13.7136 - val_accuracy: 0.1351\n",
      "Epoch 339/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.7058 - accuracy: 0.3257 - val_loss: 13.9541 - val_accuracy: 0.1380\n",
      "Epoch 340/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.6995 - accuracy: 0.3291 - val_loss: 14.1667 - val_accuracy: 0.1400\n",
      "Epoch 341/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 2.7295 - accuracy: 0.3224 - val_loss: 13.8404 - val_accuracy: 0.1354\n",
      "Epoch 342/500\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 2.7005 - accuracy: 0.3312 - val_loss: 14.1188 - val_accuracy: 0.1391\n",
      "Epoch 343/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.6759 - accuracy: 0.3335 - val_loss: 14.0787 - val_accuracy: 0.1389\n",
      "Epoch 344/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.7055 - accuracy: 0.3276 - val_loss: 13.5847 - val_accuracy: 0.1371\n",
      "Epoch 345/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.6835 - accuracy: 0.3349 - val_loss: 13.8778 - val_accuracy: 0.1391\n",
      "Epoch 346/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.6673 - accuracy: 0.3368 - val_loss: 14.0953 - val_accuracy: 0.1380\n",
      "Epoch 347/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.6703 - accuracy: 0.3301 - val_loss: 14.0091 - val_accuracy: 0.1377\n",
      "Epoch 348/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.6711 - accuracy: 0.3373 - val_loss: 14.3195 - val_accuracy: 0.1397\n",
      "Epoch 349/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.6816 - accuracy: 0.3358 - val_loss: 14.0938 - val_accuracy: 0.1397\n",
      "Epoch 350/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.6708 - accuracy: 0.3320 - val_loss: 14.2062 - val_accuracy: 0.1377\n",
      "Epoch 351/500\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 2.6463 - accuracy: 0.3418 - val_loss: 14.1143 - val_accuracy: 0.1334\n",
      "Epoch 352/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.6542 - accuracy: 0.3339 - val_loss: 14.2198 - val_accuracy: 0.1377\n",
      "Epoch 353/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.6283 - accuracy: 0.3418 - val_loss: 14.0593 - val_accuracy: 0.1383\n",
      "Epoch 354/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.6436 - accuracy: 0.3394 - val_loss: 14.0708 - val_accuracy: 0.1369\n",
      "Epoch 355/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.6240 - accuracy: 0.3454 - val_loss: 14.3519 - val_accuracy: 0.1351\n",
      "Epoch 356/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.6244 - accuracy: 0.3447 - val_loss: 14.4017 - val_accuracy: 0.1351\n",
      "Epoch 357/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.6340 - accuracy: 0.3388 - val_loss: 14.1418 - val_accuracy: 0.1414\n",
      "Epoch 358/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.6060 - accuracy: 0.3476 - val_loss: 14.4147 - val_accuracy: 0.1334\n",
      "Epoch 359/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.6103 - accuracy: 0.3459 - val_loss: 14.3817 - val_accuracy: 0.1351\n",
      "Epoch 360/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.6076 - accuracy: 0.3464 - val_loss: 14.2622 - val_accuracy: 0.1340\n",
      "Epoch 361/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 2.5966 - accuracy: 0.3425 - val_loss: 14.5247 - val_accuracy: 0.1363\n",
      "Epoch 362/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.5946 - accuracy: 0.3528 - val_loss: 14.5570 - val_accuracy: 0.1363\n",
      "Epoch 363/500\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 2.5788 - accuracy: 0.3491 - val_loss: 14.3820 - val_accuracy: 0.1340\n",
      "Epoch 364/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.5751 - accuracy: 0.3524 - val_loss: 14.4959 - val_accuracy: 0.1363\n",
      "Epoch 365/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.5675 - accuracy: 0.3498 - val_loss: 14.4576 - val_accuracy: 0.1366\n",
      "Epoch 366/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.5683 - accuracy: 0.3518 - val_loss: 14.3823 - val_accuracy: 0.1374\n",
      "Epoch 367/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.5635 - accuracy: 0.3517 - val_loss: 14.7005 - val_accuracy: 0.1380\n",
      "Epoch 368/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.5477 - accuracy: 0.3539 - val_loss: 14.4998 - val_accuracy: 0.1346\n",
      "Epoch 369/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.5622 - accuracy: 0.3556 - val_loss: 14.7981 - val_accuracy: 0.1377\n",
      "Epoch 370/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.5383 - accuracy: 0.3586 - val_loss: 14.7366 - val_accuracy: 0.1351\n",
      "Epoch 371/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 2.5574 - accuracy: 0.3533 - val_loss: 14.6385 - val_accuracy: 0.1374\n",
      "Epoch 372/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.5421 - accuracy: 0.3541 - val_loss: 14.7271 - val_accuracy: 0.1346\n",
      "Epoch 373/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.5271 - accuracy: 0.3601 - val_loss: 14.6199 - val_accuracy: 0.1371\n",
      "Epoch 374/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.5302 - accuracy: 0.3592 - val_loss: 14.6446 - val_accuracy: 0.1386\n",
      "Epoch 375/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.5218 - accuracy: 0.3574 - val_loss: 14.8760 - val_accuracy: 0.1366\n",
      "Epoch 376/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.5224 - accuracy: 0.3588 - val_loss: 14.8724 - val_accuracy: 0.1343\n",
      "Epoch 377/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.5352 - accuracy: 0.3569 - val_loss: 14.9539 - val_accuracy: 0.1380\n",
      "Epoch 378/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.5397 - accuracy: 0.3559 - val_loss: 14.8071 - val_accuracy: 0.1369\n",
      "Epoch 379/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.4960 - accuracy: 0.3651 - val_loss: 14.9038 - val_accuracy: 0.1383\n",
      "Epoch 380/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.4859 - accuracy: 0.3685 - val_loss: 14.5612 - val_accuracy: 0.1386\n",
      "Epoch 381/500\n",
      "110/110 [==============================] - 12s 114ms/step - loss: 2.5133 - accuracy: 0.3593 - val_loss: 15.0445 - val_accuracy: 0.1386\n",
      "Epoch 382/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.4894 - accuracy: 0.3656 - val_loss: 14.8656 - val_accuracy: 0.1380\n",
      "Epoch 383/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.4654 - accuracy: 0.3624 - val_loss: 14.9088 - val_accuracy: 0.1417\n",
      "Epoch 384/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.4812 - accuracy: 0.3646 - val_loss: 14.9662 - val_accuracy: 0.1389\n",
      "Epoch 385/500\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 2.4723 - accuracy: 0.3666 - val_loss: 15.2527 - val_accuracy: 0.1389\n",
      "Epoch 386/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.4586 - accuracy: 0.3688 - val_loss: 15.2888 - val_accuracy: 0.1394\n",
      "Epoch 387/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.4833 - accuracy: 0.3690 - val_loss: 15.1629 - val_accuracy: 0.1371\n",
      "Epoch 388/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.4512 - accuracy: 0.3680 - val_loss: 15.1363 - val_accuracy: 0.1357\n",
      "Epoch 389/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.4613 - accuracy: 0.3679 - val_loss: 15.3825 - val_accuracy: 0.1383\n",
      "Epoch 390/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.4502 - accuracy: 0.3715 - val_loss: 15.0192 - val_accuracy: 0.1357\n",
      "Epoch 391/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 2.4344 - accuracy: 0.3757 - val_loss: 15.3456 - val_accuracy: 0.1400\n",
      "Epoch 392/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.4404 - accuracy: 0.3739 - val_loss: 15.0968 - val_accuracy: 0.1406\n",
      "Epoch 393/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.4178 - accuracy: 0.3715 - val_loss: 15.4606 - val_accuracy: 0.1377\n",
      "Epoch 394/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.4242 - accuracy: 0.3773 - val_loss: 15.3943 - val_accuracy: 0.1423\n",
      "Epoch 395/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.4130 - accuracy: 0.3777 - val_loss: 15.1125 - val_accuracy: 0.1437\n",
      "Epoch 396/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.4150 - accuracy: 0.3739 - val_loss: 15.2388 - val_accuracy: 0.1417\n",
      "Epoch 397/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.4120 - accuracy: 0.3783 - val_loss: 15.5395 - val_accuracy: 0.1386\n",
      "Epoch 398/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.3936 - accuracy: 0.3829 - val_loss: 15.5895 - val_accuracy: 0.1360\n",
      "Epoch 399/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.3984 - accuracy: 0.3864 - val_loss: 15.2706 - val_accuracy: 0.1377\n",
      "Epoch 400/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.4277 - accuracy: 0.3748 - val_loss: 15.1802 - val_accuracy: 0.1351\n",
      "Epoch 401/500\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 2.3977 - accuracy: 0.3793 - val_loss: 15.1754 - val_accuracy: 0.1414\n",
      "Epoch 402/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 2.3922 - accuracy: 0.3791 - val_loss: 15.5006 - val_accuracy: 0.1394\n",
      "Epoch 403/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.3824 - accuracy: 0.3820 - val_loss: 15.4758 - val_accuracy: 0.1349\n",
      "Epoch 404/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.3898 - accuracy: 0.3829 - val_loss: 15.3440 - val_accuracy: 0.1417\n",
      "Epoch 405/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.3728 - accuracy: 0.3854 - val_loss: 15.9059 - val_accuracy: 0.1457\n",
      "Epoch 406/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.3753 - accuracy: 0.3873 - val_loss: 15.7442 - val_accuracy: 0.1414\n",
      "Epoch 407/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.3624 - accuracy: 0.3861 - val_loss: 15.9274 - val_accuracy: 0.1397\n",
      "Epoch 408/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.3657 - accuracy: 0.3831 - val_loss: 15.5677 - val_accuracy: 0.1391\n",
      "Epoch 409/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.3500 - accuracy: 0.3956 - val_loss: 15.9220 - val_accuracy: 0.1409\n",
      "Epoch 410/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.3412 - accuracy: 0.3937 - val_loss: 15.7880 - val_accuracy: 0.1403\n",
      "Epoch 411/500\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 2.3515 - accuracy: 0.3893 - val_loss: 16.0426 - val_accuracy: 0.1417\n",
      "Epoch 412/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.3529 - accuracy: 0.3922 - val_loss: 15.4156 - val_accuracy: 0.1377\n",
      "Epoch 413/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.3181 - accuracy: 0.3981 - val_loss: 15.8093 - val_accuracy: 0.1389\n",
      "Epoch 414/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.3611 - accuracy: 0.3897 - val_loss: 15.8061 - val_accuracy: 0.1397\n",
      "Epoch 415/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.3365 - accuracy: 0.3959 - val_loss: 15.7570 - val_accuracy: 0.1420\n",
      "Epoch 416/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.3128 - accuracy: 0.3951 - val_loss: 15.7840 - val_accuracy: 0.1389\n",
      "Epoch 417/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.3301 - accuracy: 0.3979 - val_loss: 15.9778 - val_accuracy: 0.1394\n",
      "Epoch 418/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.3131 - accuracy: 0.4036 - val_loss: 15.8189 - val_accuracy: 0.1431\n",
      "Epoch 419/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.3239 - accuracy: 0.3954 - val_loss: 15.9239 - val_accuracy: 0.1417\n",
      "Epoch 420/500\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 2.3050 - accuracy: 0.4011 - val_loss: 15.9620 - val_accuracy: 0.1357\n",
      "Epoch 421/500\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 2.2874 - accuracy: 0.3991 - val_loss: 16.4102 - val_accuracy: 0.1411\n",
      "Epoch 422/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.2976 - accuracy: 0.3994 - val_loss: 15.9457 - val_accuracy: 0.1417\n",
      "Epoch 423/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.2958 - accuracy: 0.3991 - val_loss: 15.9686 - val_accuracy: 0.1389\n",
      "Epoch 424/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.2875 - accuracy: 0.3997 - val_loss: 16.0647 - val_accuracy: 0.1389\n",
      "Epoch 425/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.2842 - accuracy: 0.4005 - val_loss: 16.1013 - val_accuracy: 0.1409\n",
      "Epoch 426/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.2876 - accuracy: 0.3977 - val_loss: 15.9686 - val_accuracy: 0.1397\n",
      "Epoch 427/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.2923 - accuracy: 0.3983 - val_loss: 15.8816 - val_accuracy: 0.1397\n",
      "Epoch 428/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.2766 - accuracy: 0.4032 - val_loss: 16.0813 - val_accuracy: 0.1391\n",
      "Epoch 429/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.2666 - accuracy: 0.4026 - val_loss: 16.2352 - val_accuracy: 0.1374\n",
      "Epoch 430/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 2.2669 - accuracy: 0.4029 - val_loss: 16.1633 - val_accuracy: 0.1391\n",
      "Epoch 431/500\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 2.2673 - accuracy: 0.4006 - val_loss: 16.0479 - val_accuracy: 0.1406\n",
      "Epoch 432/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.2564 - accuracy: 0.4116 - val_loss: 16.3891 - val_accuracy: 0.1320\n",
      "Epoch 433/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.2376 - accuracy: 0.4036 - val_loss: 16.4585 - val_accuracy: 0.1323\n",
      "Epoch 434/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.2660 - accuracy: 0.4064 - val_loss: 16.2016 - val_accuracy: 0.1337\n",
      "Epoch 435/500\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 2.2322 - accuracy: 0.4066 - val_loss: 16.3573 - val_accuracy: 0.1417\n",
      "Epoch 436/500\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 2.2442 - accuracy: 0.4107 - val_loss: 16.3656 - val_accuracy: 0.1389\n",
      "Epoch 437/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 2.2448 - accuracy: 0.4060 - val_loss: 16.4123 - val_accuracy: 0.1369\n",
      "Epoch 438/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.2344 - accuracy: 0.4139 - val_loss: 16.4267 - val_accuracy: 0.1389\n",
      "Epoch 439/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.2253 - accuracy: 0.4122 - val_loss: 16.1611 - val_accuracy: 0.1349\n",
      "Epoch 440/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 2.2057 - accuracy: 0.4215 - val_loss: 16.1791 - val_accuracy: 0.1386\n",
      "Epoch 441/500\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 2.2183 - accuracy: 0.4151 - val_loss: 16.5935 - val_accuracy: 0.1397\n",
      "Epoch 442/500\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 2.2086 - accuracy: 0.4171 - val_loss: 16.8556 - val_accuracy: 0.1363\n",
      "Epoch 443/500\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 2.2108 - accuracy: 0.4126 - val_loss: 16.4731 - val_accuracy: 0.1340\n",
      "Epoch 444/500\n",
      "110/110 [==============================] - 1255s 12s/step - loss: 2.2225 - accuracy: 0.4131 - val_loss: 16.7218 - val_accuracy: 0.1371\n",
      "Epoch 445/500\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 2.2047 - accuracy: 0.4162 - val_loss: 16.4579 - val_accuracy: 0.1326\n",
      "Epoch 446/500\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 2.1979 - accuracy: 0.4187 - val_loss: 16.3676 - val_accuracy: 0.1351\n",
      "Epoch 447/500\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 2.2049 - accuracy: 0.4126 - val_loss: 16.9110 - val_accuracy: 0.1394\n",
      "Epoch 448/500\n",
      "110/110 [==============================] - 12s 114ms/step - loss: 2.1805 - accuracy: 0.4216 - val_loss: 17.2370 - val_accuracy: 0.1386\n",
      "Epoch 449/500\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 2.1753 - accuracy: 0.4209 - val_loss: 16.5254 - val_accuracy: 0.1380\n",
      "Epoch 450/500\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 2.1748 - accuracy: 0.4234 - val_loss: 16.6179 - val_accuracy: 0.1394\n",
      "Epoch 451/500\n",
      "110/110 [==============================] - 13s 123ms/step - loss: 2.1879 - accuracy: 0.4209 - val_loss: 16.9102 - val_accuracy: 0.1380\n",
      "Epoch 452/500\n",
      "110/110 [==============================] - 17s 156ms/step - loss: 2.1903 - accuracy: 0.4204 - val_loss: 16.5169 - val_accuracy: 0.1403\n",
      "Epoch 453/500\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 2.1590 - accuracy: 0.4255 - val_loss: 16.4910 - val_accuracy: 0.1397\n",
      "Epoch 454/500\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 2.1637 - accuracy: 0.4276 - val_loss: 16.8124 - val_accuracy: 0.1406\n",
      "Epoch 455/500\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 2.1387 - accuracy: 0.4305 - val_loss: 16.9901 - val_accuracy: 0.1406\n",
      "Epoch 456/500\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 2.1495 - accuracy: 0.4324 - val_loss: 16.4890 - val_accuracy: 0.1383\n",
      "Epoch 457/500\n",
      "110/110 [==============================] - 15s 138ms/step - loss: 2.1478 - accuracy: 0.4277 - val_loss: 17.0606 - val_accuracy: 0.1409\n",
      "Epoch 458/500\n",
      "110/110 [==============================] - 15s 140ms/step - loss: 2.1529 - accuracy: 0.4301 - val_loss: 16.8297 - val_accuracy: 0.1397\n",
      "Epoch 459/500\n",
      "110/110 [==============================] - 16s 142ms/step - loss: 2.1575 - accuracy: 0.4239 - val_loss: 16.8365 - val_accuracy: 0.1420\n",
      "Epoch 460/500\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 2.1338 - accuracy: 0.4302 - val_loss: 16.9594 - val_accuracy: 0.1411\n",
      "Epoch 461/500\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 2.1227 - accuracy: 0.4371 - val_loss: 17.1994 - val_accuracy: 0.1374\n",
      "Epoch 462/500\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 2.1219 - accuracy: 0.4278 - val_loss: 17.1129 - val_accuracy: 0.1446\n",
      "Epoch 463/500\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 2.1481 - accuracy: 0.4343 - val_loss: 17.1416 - val_accuracy: 0.1434\n",
      "Epoch 464/500\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 2.1321 - accuracy: 0.4301 - val_loss: 17.1555 - val_accuracy: 0.1423\n",
      "Epoch 465/500\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 2.1132 - accuracy: 0.4349 - val_loss: 17.0033 - val_accuracy: 0.1409\n",
      "Epoch 466/500\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 2.1123 - accuracy: 0.4339 - val_loss: 17.3647 - val_accuracy: 0.1391\n",
      "Epoch 467/500\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 2.1011 - accuracy: 0.4410 - val_loss: 16.9945 - val_accuracy: 0.1386\n",
      "Epoch 468/500\n",
      "110/110 [==============================] - 15s 140ms/step - loss: 2.1044 - accuracy: 0.4331 - val_loss: 16.9458 - val_accuracy: 0.1394\n",
      "Epoch 469/500\n",
      "110/110 [==============================] - 16s 142ms/step - loss: 2.0909 - accuracy: 0.4422 - val_loss: 17.2104 - val_accuracy: 0.1414\n",
      "Epoch 470/500\n",
      "110/110 [==============================] - 16s 143ms/step - loss: 2.1105 - accuracy: 0.4344 - val_loss: 17.2647 - val_accuracy: 0.1414\n",
      "Epoch 471/500\n",
      "110/110 [==============================] - 16s 142ms/step - loss: 2.1066 - accuracy: 0.4374 - val_loss: 17.4146 - val_accuracy: 0.1374\n",
      "Epoch 472/500\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 2.0736 - accuracy: 0.4455 - val_loss: 17.1726 - val_accuracy: 0.1351\n",
      "Epoch 473/500\n",
      "110/110 [==============================] - 15s 140ms/step - loss: 2.0898 - accuracy: 0.4458 - val_loss: 17.5741 - val_accuracy: 0.1400\n",
      "Epoch 474/500\n",
      "110/110 [==============================] - 16s 143ms/step - loss: 2.0780 - accuracy: 0.4417 - val_loss: 17.4437 - val_accuracy: 0.1443\n",
      "Epoch 475/500\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 2.0804 - accuracy: 0.4404 - val_loss: 17.2524 - val_accuracy: 0.1423\n",
      "Epoch 476/500\n",
      "110/110 [==============================] - 16s 141ms/step - loss: 2.0588 - accuracy: 0.4427 - val_loss: 17.4510 - val_accuracy: 0.1437\n",
      "Epoch 477/500\n",
      "110/110 [==============================] - 16s 143ms/step - loss: 2.0667 - accuracy: 0.4452 - val_loss: 17.3277 - val_accuracy: 0.1377\n",
      "Epoch 478/500\n",
      "110/110 [==============================] - 16s 143ms/step - loss: 2.0833 - accuracy: 0.4416 - val_loss: 17.1296 - val_accuracy: 0.1386\n",
      "Epoch 479/500\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 2.0607 - accuracy: 0.4516 - val_loss: 17.5794 - val_accuracy: 0.1426\n",
      "Epoch 480/500\n",
      "110/110 [==============================] - 15s 137ms/step - loss: 2.0577 - accuracy: 0.4488 - val_loss: 17.5908 - val_accuracy: 0.1403\n",
      "Epoch 481/500\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 2.0580 - accuracy: 0.4508 - val_loss: 18.1207 - val_accuracy: 0.1394\n",
      "Epoch 482/500\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 2.0588 - accuracy: 0.4458 - val_loss: 17.3163 - val_accuracy: 0.1414\n",
      "Epoch 483/500\n",
      "110/110 [==============================] - 15s 138ms/step - loss: 2.0469 - accuracy: 0.4496 - val_loss: 17.3266 - val_accuracy: 0.1374\n",
      "Epoch 484/500\n",
      "110/110 [==============================] - 16s 143ms/step - loss: 2.0320 - accuracy: 0.4516 - val_loss: 17.8287 - val_accuracy: 0.1391\n",
      "Epoch 485/500\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 2.0414 - accuracy: 0.4523 - val_loss: 17.6964 - val_accuracy: 0.1383\n",
      "Epoch 486/500\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 2.0498 - accuracy: 0.4452 - val_loss: 17.5829 - val_accuracy: 0.1377\n",
      "Epoch 487/500\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 2.0212 - accuracy: 0.4559 - val_loss: 17.6716 - val_accuracy: 0.1374\n",
      "Epoch 488/500\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 2.0146 - accuracy: 0.4593 - val_loss: 17.9630 - val_accuracy: 0.1400\n",
      "Epoch 489/500\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 2.0418 - accuracy: 0.4504 - val_loss: 17.4794 - val_accuracy: 0.1389\n",
      "Epoch 490/500\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 2.0102 - accuracy: 0.4598 - val_loss: 17.7470 - val_accuracy: 0.1403\n",
      "Epoch 491/500\n",
      "110/110 [==============================] - 17s 156ms/step - loss: 2.0051 - accuracy: 0.4596 - val_loss: 17.9719 - val_accuracy: 0.1409\n",
      "Epoch 492/500\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 2.0317 - accuracy: 0.4522 - val_loss: 17.5925 - val_accuracy: 0.1360\n",
      "Epoch 493/500\n",
      "110/110 [==============================] - 17s 154ms/step - loss: 2.0140 - accuracy: 0.4556 - val_loss: 17.6850 - val_accuracy: 0.1363\n",
      "Epoch 494/500\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 1.9990 - accuracy: 0.4604 - val_loss: 17.8139 - val_accuracy: 0.1351\n",
      "Epoch 495/500\n",
      "110/110 [==============================] - 16s 142ms/step - loss: 1.9901 - accuracy: 0.4600 - val_loss: 17.9921 - val_accuracy: 0.1383\n",
      "Epoch 496/500\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 2.0031 - accuracy: 0.4566 - val_loss: 17.8302 - val_accuracy: 0.1360\n",
      "Epoch 497/500\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 1.9878 - accuracy: 0.4598 - val_loss: 17.7468 - val_accuracy: 0.1423\n",
      "Epoch 498/500\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 1.9844 - accuracy: 0.4596 - val_loss: 18.0959 - val_accuracy: 0.1409\n",
      "Epoch 499/500\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 1.9910 - accuracy: 0.4609 - val_loss: 18.0234 - val_accuracy: 0.1374\n",
      "Epoch 500/500\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 1.9849 - accuracy: 0.4592 - val_loss: 18.2830 - val_accuracy: 0.1366\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=y_train, epochs=500, batch_size=128, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'],label='train')\n",
    "plt.plot(history.history['val_accuracy'],label='test')\n",
    "plt.title(\"Acuracy Comparison\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Original Sentence:  anyway because they don't want to go away from what they're doing which is crazy because it is they're doing \n",
      "\n",
      "Actual Sentence:  anyway because they don't want to go away from what they're doing which is crazy because it is they're doing very poorly while the social and socialist democrats are trying to destroy american healthcare and your social security they're putting \n",
      "\n",
      "Generated Sentence:  anyway because they don't want to go away from what they're doing which is crazy because it is they're doing all too many right and they're not getting all great people that again and we have a lot of doesn't\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(420)\n",
    "seed = 20\n",
    "new = 20\n",
    "\n",
    "rand_seq = random.choice(sequences)\n",
    "\n",
    "start_idx = random.randint(0, len(rand_seq) - seed - 5)\n",
    "\n",
    "end_idx = start_idx+seed\n",
    "\n",
    "sent = rand_seq[start_idx: end_idx]\n",
    "original_sent = [idx_text[i] for i in sent]\n",
    "actual = sent[:] + rand_seq[end_idx:end_idx+new]\n",
    "\n",
    "generated = sent[:]\n",
    "for i in range(new):\n",
    "    pred = np.argmax(model.predict(np.array(sent).reshape(1,-1)), axis=-1)\n",
    "    new_idx = np.max(pred)\n",
    "    sent+=[new_idx]\n",
    "    generated.append(new_idx)\n",
    "\n",
    "print('Original Sentence: ', ' '.join(original_sent), '\\n')\n",
    "print('Actual Sentence: ', ' '.join([idx_text[i] for i in actual]), '\\n')\n",
    "print('Generated Sentence: ', ' '.join([idx_text[i] for i in generated]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
